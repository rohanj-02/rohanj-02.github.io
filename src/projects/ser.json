{
	"name": "Speech Emotion Recognition",
	"description": "Implemented state-of-the-art DL models to recognise emotions from speech. Used MFCC and spectrogram features from audio as input to the CNN model on top of fine-tuned AlexNet with an attention mechanism to reach an accuracy of 82% on the EMO DB dataset.",
	"images": [],
	"docs": ["/docs/SER_Paper.pdf"],
	"technologies": ["Pytorch"]
}
